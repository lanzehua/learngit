# 10.9日论文 

---

学习将纹理显著性自适应注意纳入图像卡通化（Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization）

icml2022

该论文提出了一个新颖的图像动漫风格迁移模型，建立了图像级与区域级并行的对抗学习，区域级分支将对抗学习约束在卡通图像纹理显著的区域，以更好地感知和传递卡通纹理特征。这种方法可以高效地深入挖掘动漫图像的纹理特征和表征分布，在多个数据集，尤其是高分辨率数据集上实现了更为显著、生动的风格渲染效果。该研究为卡通风格迁移的研究开创了新的思路。



摘要——从无监督图像到图像翻译的角度来看，图像卡通最近由生成对抗网络（GANs）主导，其中一个固有的挑战是精确捕捉和充分转移特征的卡通风格（如清晰的边缘、平滑的色彩阴影、抽象的精细结构等）。

Existing advanced models try toenhance cartoonization effect by learning to promote edges adversarially, introducing style transfer loss, or learning to align stylefrom multiple representation space.

本文证明，仅需基本的对抗性损失，就可以实现更清晰、生动的制图效果。观察到卡通风格在卡通纹理显著的局部图像区域更加明显，我们构建了一个与正常图像级并行的区域级对抗性学习分支，它限制了对卡通纹理显著的局部斑块的对抗性学习，以更好地感知和传递卡通纹理特征。

CTSs模块： cartoon texture salience sampler

为此，提出了一种新的卡通纹理显著性采样器（CTSS）模块，从训练数据中动态采样卡通纹理显著性斑块。通过大量的实验，我们证明了对抗性学习中的纹理显著性自适应注意作为图像卡通化中相关方法缺失的组成部分，在促进和增强图像卡通风格化方面具有重要意义，特别是对于高分辨率的输入图片。

随后介绍针对图像卡通化的已有方法：图像平滑、颜色量化；（iii）边缘增强；（虽然它们成功地模仿了一些重要的卡通特征，但它们缺乏数据驱动的学习能力来更深入地捕捉卡通风格。）

![image-20221009095844179](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009095844179.png)

然后简单叙述GAN参与图像卡通化的原理：

它可以表述为一个无监督的图像到图像转换问题，其目标是从自然图像的源域X→Y学习保留内容的图像转换映射X到卡通图像的目标域Y。一般的框架是通过对抗性学习将生成图像的风格分布与目标域真实漫画的风格分布对齐，同时约束输入照片和生成结果之间的感知内容一致性，避免内容不匹配。然而，很难产生具有足够显著的卡通特征的结果，因此一些先进的方法在一般框架的基础上进一步提高了卡通化效果。

经典之作CartoonGAN：提出了一种新的**促进边缘的对抗性损失**来突出典型的边缘清晰度的卡通特征。该损失函数强制鉴别器不仅区分真实的卡通图像和合成的图像，而且区分边缘平滑的卡通图像，从而引导生成器产生更清晰的边缘，欺骗鉴别器。

AnimeGAN [7]将Gram损失[8]，一种经典的基于纹理描述符的风格损失，引入到GAN框架中，以增强学习卡通纹理模式。然而，它对加强卡通纹理转移的作用仍不那么明显。最近，提出了一种白盒图像卡通化框架[9]。它将图像分解为多个表示，并学习在每个表示的流形中对齐样式。该方法提出了一种自适应着色算法，生成图像颜色分割地图，模拟卡通图像的稀疏色块，带来视觉上的卡通风格。然而，生成的结果的卡通抽象性和生动度仍然不那么突出，特别是对于高分辨率的输入图像。$\color{#FF0000}{建议下次这么写的时候标出来哪里不好了！}$



上述模型采用不同的方法来弥补在充分转移卡通风格时基本对抗性损失的局限性。然而，我们认为弱程式化问题不是由于对抗性损失的能力本身，而是由于突出的卡通纹理特征的非全局分布。例如，清晰的边缘通常分布在局部区域，而不是整个图像，并且清晰的边缘的像素比例也很小。$\color{#FF0000}{因此，当在整个图像的尺度上进行基本的对抗性损失训练时，边缘清晰度的特征很容易被更明显的全局特征所压倒，如颜色阴影的平滑度。}$

$\color{#0000ff}{这启发我们关注卡通纹理突出的局部区域，以便更好地感知和传递卡通纹理特征。}$

$\color{FF0000}{}$​同样的关注图像补丁的局部分布的思想在许多其他计算机视觉领域也被广泛探索，如图像分类[10]、[11]、[12]、图像恢复[13]、[14]、[15]、目标检测[16]、[17]、[18]等。

本文作者的意见$\Uparrow$





![image-20221009103920851](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009103920851.png)

为了增强卡通纹理模式的传输，我们自适应地约束了卡通纹理的局部图像区域的补丁级对抗性学习，提出了一种新的卡通纹理采样器（CTSS）模块，从每个小批训练图像中动态提取具有最显著卡通纹理模式的图像块。

通过将纹理显著性自适应注意纳入对抗性学习，典型的卡通纹理特征被更充分地转移，产生更抽象、生动的卡通效果。我们的模型的示例结果如图1所示。我们的方法绕过了单独的边缘平滑数据准备阶段，使用额外的风格损失，以及复杂的表示提取过程，同时产生更突出的卡通效果，特别是对于大的输入图片。



随后是简单的综述：

1. 神经样式传输（NST）最初是被提出的一种基于在线优化的算法，通过最小化克损失[8]来迭代传输图像样式。然后，通过训练一个前馈网络[19]，[20]，将其转化为一个离线生成模型，以满足实时应用程序的需求。后来，人们努力将快速NST从单一风格扩展到多种风格的[21]，[22]，甚至是任意风格的[23]，[24]。除革兰氏损失外，还先后提出了各种风格损失，如MMD损失[25]、CNNMRF损失[26]、上下文损失[27]和松弛EMD损失[28]。这些损失函数适合于从单一图像传输低级纹理特征。相比之下，跨域样式转移方法使用对抗性损失来自动从风格上相似的图像集合中学习高级样式。通过GANs，风格转移问题得到了更多的应用，如字体风格转移[29]、[30]、绘画风格转移[31]、[32]、化妆风格转移[33]等。
2. 图像-图像转换是指图像从源域到目标域的转换，根据两个域的配对训练数据是否可用，可分为监督和无监督情况。对于监督问题，Pix2Pix [34]将条件GAN与图像级稀疏L1正则化相结合，可以很好地推广到图像超分辨率[35]、图像去噪[36]、语义图像合成[37]等许多应用中。对于后一种情况，CycleGAN [38]和UNIT [39]分别是基于周期一致性约束和共享潜在空间假设实现无监督图像平移的典型模型。然后，将StarGAN [40]和AttGAN [41]等方法通过将条件GAN与辅助域分类器相结合，将翻译从两个域扩展到多个域。此外，在多模态翻译[42]、[43]和少样本学习[44]领域也探讨了这个问题。





卡通图像有光滑的阴影和生动的色彩。除了这些代表整体像素分布的全局特征外，卡通图像最显著的特征是其独特的纹理模式，代表局部像素分布。具体来说，高频像素集中在边缘上，而低频像素则平滑地分布在边缘旁边。这种明显的高频和低频像素的分离明显不同于自然图像，其中高频和低频元素紧密地交织在一起。然而，如图3所示，![image-20221009110912582](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009110912582.png)这种卡通纹理图案只在边缘清晰的部分图像区域中明显出现，这意味着潜在的卡通纹理图案从边缘不同的局部区域的视角中比从整个图像的视角中更容易感知。因此，我们附加了一个补丁级学习分支，它自适应地对边缘不同的局部区域应用对抗性学习，以增强对卡通纹理模式的捕获。

$\Uparrow$作者想法来源

![image-20221009110544141](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009110544141.png)



![image-20221009110951558](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009110951558.png)

![image-20221009111059240](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009111059240.png)

![image-20221009111106384](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009111106384.png)

自己看英文描述还是可以很容易的理解本文的；



由于独特的卡通纹理模式在边缘不同的局部区域视觉上更突出，我们的CTSS模块自适应地从每个输入的小批图像中采样具有最不同边缘的局部图像块，实现细节如图2所示

对于边缘处理的步骤原理：考虑到局部斑块不能反映图像的整体颜色分布，我们最终将采样的Cpatch转换为灰度，以学习颜色不变的局部卡通纹理模式。由于我们使用基于梯度的滤波方法来检测边缘，一些没有清晰边缘但有大量噪声的局部斑块仍然可以有较大的累积梯度，因此被采样进行斑块级训练。因此，我们应用引导滤波(Eq。1)在边缘提取前的边缘保留图像去噪。2)，这就保证了图像补丁是由于清晰的边缘而被采样出来的，而不是由于较大的噪声。

**tips：本模型可以考虑用于物品检测的边缘检测吗。请自己留意**



内容损失基本上成熟了使用vgg19进行pre训练就行。

gan损失采用lsgan（最小二乘法gan）的损失函数

![image-20221009140036464](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009140036464.png)

如图所示，YUVformat及其转换操作。[什么是YUV?](https://zhuanlan.zhihu.com/p/384455058)

> 引用标记	 

![image-20221009140653218](C:\Users\lzhrt\AppData\Roaming\Typora\typora-user-images\image-20221009140653218.png)

然后是正常的gan优化流程

conclusion：本文提出了一种用于图像制图的深度生成模型。我们用补丁级学习分支补充了正常的图像级对抗训练，并仅在卡通纹理存在的局部区域自适应地约束补丁级对抗学习，以增强卡通纹理模式的捕获。为此，提出了一种新的卡通纹理显著采样器（CTSS）模块，以动态采样包含最显著卡通纹理特征的局部图像块。通过将这种纹理显著性的自适应注意纳入对抗性学习，我们的方法能够明显地转移更抽象和生动的卡通风格。

